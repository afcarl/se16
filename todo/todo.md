<<<<<<< HEAD
## On the assignment
https://github.com/ds4se/chapters/blob/master/muench/Chapter_Muench.md

Every Idea can be Tested with an Experiment

A means for doing this is continuously conducting experiments to test assumptions and making being wrong cheaper. Insights from experiments directly influence frequent deliveries. This process of continuous experimentation consists of three meta-steps:

Break down your product idea into a product roadmap that can be efficiently tested. Be aware that the roadmap changes over time and is basically a list of assumptions.

Run frequent and additive experiments to test assumptions. This includes systematically observing usersâ€™ behavioral responses to stimuli such as features. Constantly reprioritize the assumptions. If an experiment does not deliver the expected result, do not test another option at random. Carefully choose what to test next.

Use results from experiments to iteratively modify your product roadmap. This might lead to an improvement of a product or a significant change of the strategy. It might also mean that you need to stop the project.

Success cases from companies such as Etsy, Amazon, and Supercell show that such an experimental approach helps companies to gain competitive advantage by reducing uncertainties and rapidly finding product roadmaps that work. However, experimentation is hard.


## age of the apps

https://github.com/ds4se/chapters/blob/master/meinagappan/miningmobileappstores.md

Recent market studies predict that the global mobile app economy is expected to be worth $143 billion by 2016 [17]. Thus there exists considerable impact in solving the challenges faced by several different stakeholders like the mobile app developers, users, and platform owners (like Apple/BlackBerry/Google/Microsoft).

Mobile apps, unlike traditional software are distributed by the developers directly to the end users via a centralized platform called the app store. Along with the executable mobile app, the app stores contain a large set of meta-data about the app. For each app any end user is able to look at the name and contact details of the developer, description, sample screenshots, feature set of the app, number of downloads and the price for the app. Additionally, the app stores allow users to post reviews of the apps. This is very different from traditional software. Mobile app developers get continuous feedback from users that can be leveraged to help them. For example, prior work leveraged user reviews to extract user-faced issues [12, 11], and new requirements [4].

Using the data from the app stores, several companies like App Annie1, (which recently bought another company - Distimo2) and Appfigures3 have even built successful businesses selling intelligence gained from observing the evolution of several hundred thousand apps in the app stores. Similar to such businesses, researchers can mine the store for meta-data of the apps and the apps themselves [3], and analyze the mined data to compile empirical results to help the various stakeholders of mobile apps. Even the feedback provided by end users on the mobile apps (including closed source apps from private companies) is publicly available in the app stores for researchers to mine.

Since 2012 [6, 20] researchers have begun to mine the data in the mobile app stores to address relevant software engineering issues. One such example is the mining of the feedback given as user reviews in mobile app stores for understanding the end user perspective. We describe some of the advancements made in this regard, below.

small enough for formal methods
=======
# editor

tinymce

or not: html, two column frame
>>>>>>> f1a0b8c3284cffbe3767a5d5cf6265ff3f8fa8bd

## On methodologies

new world of dev ops: need a primer on auto deployment, autimated unit test, autoomated system texting, coe review,
datk launching, end-user commun, feature flags, telementr, bnranching, change owenrship,.staging

https://mail.google.com/mail/u/0/#all/151b7677624b9f20

## on design (and the need for feedback)

Just about 20% of the features implemented in a software product are often or always used, while 64% of the features get rarely or never used [6]. This means that substantial development effort is wasted. But even worse: it means that maintenance cost of the product (constituting the majority of the total product effort) is higher than needed. This often implies delays in delivering products or lack of quality
[6] Standish (2002). "What are your Requirements?" retrieved from http://www.standishgroup.com/.

aslo that thing with ms windows where mot functions not used

https://blogs.msdn.microsoft.com/b8/2011/08/29/improvements-in-windows-explorer/


Gail C. Murphy, Mik Kersten, Leah Findlater: How Are Java Software Developers Using the Eclipse IDE? IEEE Software 23(4): 76-83 (2006)
attached 

## on the value of code reviews

https://github.com/ds4se/chapters/blob/master/jacekczerwonka/code_reviews.md : 
most value of code review NOT finding defects

[2] Alberto Bacchelli and Christian Bird. 2013. Expectations, outcomes, and challenges of modern code review. In Proceedings of the 2013 International Conference on Software Engineering (ICSE '13). IEEE Press, Piscataway, NJ, USA, 712-721.


## testing less

track what was effective at finding bugs. test those more.
https://github.com/ds4se/chapters/blob/master/kim_herzig/test_data.md

more complex
http://cse.unl.edu/~elbaum/pre-prints/fse2014-prePrint.pdf
