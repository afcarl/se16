# Effort Estimation

How much effort does it take to build software? Is
this an important question? Is this an answerable question?

## Why?

According to the extensive systematic review by
Jorgensen and Shepperd[^jos97], developing new
estimation models is the biggest research topic in
SEE since 1980s.

Over or underestimation of software development
effort can lead to undesirable results:
Underestimation results in schedule and budget
overruns, which may cause project cancellation.
Overestimation hinders the acceptance of promising
ideas, thus threatening organizational
competitiveness.

When projects start running out of budget, bad things happen.
The first thing to go is all pretense of quality assurance
Finally, the whole project can get cancelled.

e.g. Software to control shuttle refurbishment "To
gain control over its finances, NASA last week
scuttled a new checkout and launch control system
(CLCS) for the space shuttle.  A recent assessment
of the CLCS, which the space agency originally
estimated would cost $206 million to field,
estimated that costs would swell to between $488
million and $533 million by the time the project was
completed.  – June 11 2003, Computer News

![clsc](_img/clcs.ong)

## Three Cultures of Estimation

Leo Breiman,
[Statistical Modeling: The Two Cultures](https://projecteuclid.org/download/pdf_1/euclid.ss/1009213726),
Statist. Sci. Volume 16, Issue 3 (2001), 199-231.

Two ways to reach conclusions from data:

1. Data is generated by a given stochastic data model (e.g. a normal distribution);
          + Traditional statistical view
          + Effort predicted via (a) assuming a background distribution; (b) fitting
		    project data to that distribution; Eg COCOMO; Eg Breiman culture1.
2. The other uses algorithmic models and treats the data mechanism as unknown.
          + Invasion of the data miners
          + E.g. Reasoning via analogy (new estimates via finding similar old projects)

And a new view:

The term #NoEstimates is specifically tied to humans
using their judgment to predict development effort
for a solution that have not yet fully developed.

1. Make Starting Amount of Money Small; Deliver
   Working Software Often
       + J.B. Rainsberger, the author of jUnit Recipes,
         points out that his first solo software project was
         just like this. Rainsberger made no promises up
         front, offering instead to show working software
          every two weeks — and also allowing the client to
          fire him with as little as two weeks' notice.
2.  Fund a Pilot That Delivers Working Software; Then Use Modeling to Forecast Schedule
       + If the effort involved for each piece of work
         averages within some reasonable deviation, the team
          can count the pieces of work accomplished per week
        and predict, in a sense, when the project will be
         done.
3. Move From Contract Negotiation to Partnership
       + _Standard way:_ The team promises to deliver something on week 30, and the two groups meet every week or two to show progress and design the next step.
       + _Another way:_ Establish scope at the outset of a project, but it lets the customer adjust and plan specifics each week. Lets the  customer could steer to a place very different that the original
	   goal. The customer gets what it needs in the moment— not what it thought it needed six months ago.

How: According to  Jorgensen~\cite{jorg04},  expert-based  best practices
include:

1. evaluate estimation accuracy, but avoid high evaluation pressure;
2. avoid conflicting estimation goals;
3. ask the estimators to justify and criticize their estimates;
4. avoid irrelevant and unreliable estimation information;
5.  use documented data from previous development tasks;
6. find estimation experts with relevant domain background;
7. estimate top-down and bottom-up, independently of each other;
8. use estimation checklists;
9. combine estimates from different experts and estimation strategies;
10. assess the uncertainty of the estimate;
11. provide feedback on estimation accuracy; and, 
12. provide estimation training opportunities.

Jorgensen also advises that experts continually re-evaluate their estimates
using feedback from real-world projects~\cite{jorgensen09,jorg11}.

Effort estimates are often wrong by a factor of
four~\cite{Boehm1981} or even more~\cite{kemerer87}.
As a result, the allocated funds may be inadequate
to develop the required project.  In the worst case,
over-running projects are canceled and the entire
development effort is wasted.  For example:

+ NASA canceled its incomplete Check-out Launch Control System project after the initial  
 $200M estimate was exceeded by another \$200M~\cite{clcs03}.
+ The  ballooning software costs of JPL's Mission Science Laboratory  
recently forced a two-year delay~\cite{jpl2008}.

Methods:

+ _Expert-based methods_ that use human expertise
(possibly augmented with process guidelines, checklists, and data) to
generate predictions~\cite{Jorgensen2004,jorg09};
+  Or 
  _model-based methods_ can summarize old data with data miners
 that make predictions about new
projects~\cite{boehm00b,me10d}.  

These methods range in complexity from:

+ Relatively simple automatic  nearest neighbor methods~\cite{Keung2008};
+ Planning poker (not for exact numbers, but to rank different stories);
+ To the more intricate tree-learning
methods used in (e.g.) CART~\cite{Breiman1984};
+ To even more complex search-based methods that, say, use tabu search
to set the  parameters of support vector regression~\cite{Corazza2010};
or very slow genetic algorithms that select the best training data~\cite{Li2009}.

## Planning Poker (from Wikipedia)

+ Planning poker, also called Scrum poker, is a
  consensus-based, gamified technique for
  estimating,
        + members of the group make estimates by playing numbered cards face-down to the table,
        instead of speaking them aloud.
		+ cards were numbered by larger and larger numbers
		   e.g. 0, ½, 1, 2, 3, 5, 8, 13, 20, 40, 100, and optionally a
		+ The cards are revealed, and the estimates are then discussed.
		+  By hiding the figures in this way, the group can avoid the cognitive bias of anchoring, where the first number spoken aloud sets a precedent for subsequent estimates.

Poorly studied:

+ Only a handful of studies: A study by
  Moløkken-Østvold and Haugen[^agile] found that
  [the] set of control tasks in the same project,
  estimated by individual experts, achieved similar
  estimation accuracy as the planning poker
  tasks. However, for both planning poker and the
  control group, measures of the median estimation
  bias indicated that both groups had unbiased
  estimates, as the typical estimated task was
  perfectly on target.
+ Where as other methods are extensively explored [^others]

[^agile]: K Moløkken-Østvold, NC Haugen (10–13 April 2007). "Combining Estimates with Planning Poker—An Empirical Study". 18th Australian Software Engineering Conference (IEEE): 349–58. doi:10.1109/ASWEC.2007.15.
[^others]: [Google scholar search of "software effort estimation", since 2012](https://goo.gl/kyjxVH)

4. Employ Stop-and-Start Heuristics
        + A great deal of portfolio management efforts consist
of trying to figure out what projects will be done
in what time, how many contractors or new hires are
needed to make the timelines line up and that sort
of work. Matt Barcomb, vice president of product
development at Taxware, suggests that might be
overthinking it. According to Barcomb, most IT organizations can
usually figure out what they should be working on
right now. If the team can develop rules of thumb,
or heuristics, around when to stop and when to
adjust, it doesn't need that kind of heavyweight
scheduling. Just work on projects until they don't
make sense, then change gears. This might make
long-term predictions challenging — but if you look
back over your team's last five-year plan, how
accurate was it, anyway?
5. Drop Estimation From Your Development Process Entirely
        + John Carmack, CEO of Id Software, is famous for the
          expression "it's done when it's done," so much so
          that the phrase appears under Carmack's name on
          WikiQuote. If your organization makes enough money to run
          itself, and if you view time spent estimating as time not developing, then you might abandon
		  estimates and just write code. This approach is extremely tempting for products that charge a
		  per-user, per-month fee that are already cash-flow positive.
		  (We used this method for some time when I belonged to the technical staff at Socialtext.)
        + Don't estimate. Do. Get an income stream on an existing
          code base, work on multiple extensions, ship the ones that
          mature.  Change work culture, reward developers that produce
          shipable products.

[boehm](_img/boehmEstimation.png)

Expert effort estimation  (e.g. planning poker, Delphi panels) are “bad"

+ Passos et al. found many commercial software
  engineers generalize from their first few projects
  to all future projects [^Pb13].
+ Jorgensen & Gruschke found commercial estimation
  “gurus” that rarely use lessons from past projects
  to improve their future estimates [^Jg09].
+ When engineers fail to revise their beliefs, this
  leads to poor Delphi-based estimates (see examples
  in [^Jg09]).
      + Hard to audit expert-based estimates
      + And some government procurement cycles require such an audit
+ Hard to understand old expert-based estimates
+ And if you are being sued, then you really want
  evidence of a defensible estimate back at start of
  project.

[^Pb13]: Carol Passos, Ana Paula Braun, Daniela
S. Cruzes, and Manoel Mendonca. Analyzing the impact
of beliefs in software project practices. In
ESEM’11, 2011.
[^Jg09]: M. Jørgensen and
T.M. Gruschke. The impact of lessons learned
sessions on effort estimation and uncertainty
assessments. Software Engineering, IEEE Transactions
on, 35(3):368 –383, May-June 2009

## Example of Parametric Analysis (Culture1)

+ Scale Drivers
      + Precedentedness	 (have we done this before)
      + Development Flexibility	
      + Architecture/Risk Resolution  (anyone looked at module interfaces)
      + Team Cohesion	
+ Process Maturity
      + Product Attributes
      + Required Reliability	
      + Database Size	
      + Product Complexity	
      + Required Reuse	
      + Documentation	
+ Platform Attributes
      + Execution Time Constraint	
      + Main Storage Constraint	
      + Platform Volatility	
      + Personnel Attributes
+ Analyst Capability	
      + Programmer Capability
      + Personnel Continuity 
      + Applications Experience
      + Platform Experience	 
      + Language and Toolset Experience	
+ Project Attributes
      + Use of Software Tools	 
      + Multisite Development	 
      + Required Development Schedule

[cocomoParems](_img/cocomoParams.png)

```python
_  = None;  Coc2tunings = [[
#              vlow  low   nom   high  vhigh  xhigh   
# scale factors:
'Flex',        5.07, 4.05, 3.04, 2.03, 1.01,     _],[
'Pmat',        7.80, 6.24, 4.68, 3.12, 1.56,     _],[
'Prec',        6.20, 4.96, 3.72, 2.48, 1.24,     _],[
'Resl',        7.07, 5.65, 4.24, 2.83, 1.41,     _],[
'Team',        5.48, 4.38, 3.29, 2.19, 1.01,     _],[

# negative effort multipliers (more means faster)        
'acap',        1.42, 1.19, 1.00, 0.85, 0.71,    _],[
'aexp',        1.22, 1.10, 1.00, 0.88, 0.81,    _],[
'ltex',        1.20, 1.09, 1.00, 0.91, 0.84,    _],[
'pcap',        1.34, 1.15, 1.00, 0.88, 0.76,    _],[ 
'pcon',        1.29, 1.12, 1.00, 0.90, 0.81,    _],[
'plex',        1.19, 1.09, 1.00, 0.91, 0.85,    _],[
'sced',        1.43, 1.14, 1.00, 1.00, 1.00,    _],[ 
'site',        1.22, 1.09, 1.00, 0.93, 0.86, 0.80],[
'tool',        1.17, 1.09, 1.00, 0.90, 0.78,    _],[

# positive effort multipliers (more means slower)
'cplx',        0.73, 0.87, 1.00, 1.17, 1.34, 1.74],[
'data',           _, 0.90, 1.00, 1.14, 1.28,    _],[
'docu',        0.81, 0.91, 1.00, 1.11, 1.23,    _],[
'pvol',           _, 0.87, 1.00, 1.15, 1.30,    _],[
'rely',        0.82, 0.92, 1.00, 1.10, 1.26,    _],[
'ruse',           _, 0.95, 1.00, 1.07, 1.15, 1.24],[ 
'stor',           _,    _, 1.00, 1.05, 1.17, 1.46],[
'time',           _,    _, 1.00, 1.11, 1.29, 1.63]]
```

```python
def COCOMO2(project,  a = 2.94, b = 0.91,  # defaults
                      tunes= Coc2tunings): # defaults 
  sfs ems, kloc  = 0,1,22          
  scaleFactors, effortMultipliers = 5, 17
  
  for i in range(scaleFactors):
    sfs += tunes[i][project[i]]
  
  for i in range(effortMultipliers):
    j = i + scaleFactors
    ems *= tunes[j][project[j]]
	
  return a * ems * project[kloc] ** (b + 0.01*sfs)
```	
	
	



## Example of analytics (Culure2)


In a nearest neighbor approach, we search a database of {\em past projects}
for examples that are nearest the {\em current project}. 
We then apply the  heuristic that {\em the present is like the past}
and return the esitmate of the nearest past project.


References
===========


[^Js07]: M. Jorgensen and M. Shepperd, "A Systematic
Review of Software Development Cost Estimation
Studies," IEEE Trans. Software Eng., vol. 33, no. 1,
pp. 33-53, Jan. 2007.
